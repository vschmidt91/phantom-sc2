{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPG Compression Benchmark\n",
    "\n",
    "This notebook benchmarks compression ratio, compression speed, and decompression speed on the `.pyd` binaries in `phantom/common/distribute/cpg`.\n",
    "\n",
    "It uses stdlib codecs by default (`zlib`, `gzip`, `bz2`, `lzma`) and will also benchmark optional codecs (`brotli`, `zstandard`, `lz4`) if installed."
   ],
   "id": "d945c77eb6a08fbe"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T00:55:37.567214700Z",
     "start_time": "2026-02-21T00:55:37.472236Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import bz2\n",
    "import gzip\n",
    "import importlib\n",
    "import lzma\n",
    "import statistics\n",
    "import time\n",
    "import zlib\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    \"\"\"Walk upwards until a directory containing `phantom/` is found.\"\"\"\n",
    "    current = (start or Path.cwd()).resolve()\n",
    "    for candidate in [current, *current.parents]:\n",
    "        if (candidate / \"phantom\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"Could not locate repository root containing `phantom/`.\")\n",
    "\n",
    "\n",
    "REPO_ROOT = find_repo_root()\n",
    "CPG_DIR = REPO_ROOT / \"phantom\" / \"common\" / \"distribute\" / \"cpg\"\n",
    "PYD_FILES = sorted(CPG_DIR.glob(\"*.pyd\"))\n",
    "\n",
    "if not PYD_FILES:\n",
    "    raise FileNotFoundError(f\"No .pyd files found in {CPG_DIR}\")\n",
    "\n",
    "print(f\"Repo root: {REPO_ROOT}\")\n",
    "print(f\"CPG dir:   {CPG_DIR}\")\n",
    "print(\"\\nInputs:\")\n",
    "for p in PYD_FILES:\n",
    "    print(f\"- {p.name:35} {p.stat().st_size / (1024 * 1024):8.3f} MiB\")\n"
   ],
   "id": "8a8b042dabd05703",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: C:\\Users\\volke\\PycharmProjects\\phantom-sc2\n",
      "CPG dir:   C:\\Users\\volke\\PycharmProjects\\phantom-sc2\\phantom\\common\\distribute\\cpg\n",
      "\n",
      "Inputs:\n",
      "- harvest1.cp312-win_amd64.pyd           0.260 MiB\n",
      "- harvest2.cp312-win_amd64.pyd           0.268 MiB\n",
      "- harvest3.cp312-win_amd64.pyd           0.295 MiB\n",
      "- harvest4.cp312-win_amd64.pyd           0.397 MiB\n",
      "- harvest5.cp312-win_amd64.pyd           0.812 MiB\n",
      "- harvest6.cp312-win_amd64.pyd           2.495 MiB\n",
      "- harvest7.cp312-win_amd64.pyd           9.256 MiB\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T00:55:37.597514600Z",
     "start_time": "2026-02-21T00:55:37.571228200Z"
    }
   },
   "source": [
    "def _build_algorithms():\n",
    "    algos = []\n",
    "\n",
    "    algos.append({\n",
    "        \"name\": \"zlib-l1\",\n",
    "        \"compress\": lambda b: zlib.compress(b, level=1),\n",
    "        \"decompress\": zlib.decompress,\n",
    "    })\n",
    "    algos.append({\n",
    "        \"name\": \"zlib-l6\",\n",
    "        \"compress\": lambda b: zlib.compress(b, level=6),\n",
    "        \"decompress\": zlib.decompress,\n",
    "    })\n",
    "    algos.append({\n",
    "        \"name\": \"zlib-l9\",\n",
    "        \"compress\": lambda b: zlib.compress(b, level=9),\n",
    "        \"decompress\": zlib.decompress,\n",
    "    })\n",
    "\n",
    "    algos.append({\n",
    "        \"name\": \"gzip-l6\",\n",
    "        \"compress\": lambda b: gzip.compress(b, compresslevel=6),\n",
    "        \"decompress\": gzip.decompress,\n",
    "    })\n",
    "\n",
    "    algos.append({\n",
    "        \"name\": \"bz2-l9\",\n",
    "        \"compress\": lambda b: bz2.compress(b, compresslevel=9),\n",
    "        \"decompress\": bz2.decompress,\n",
    "    })\n",
    "\n",
    "    algos.append({\n",
    "        \"name\": \"lzma-p6\",\n",
    "        \"compress\": lambda b: lzma.compress(b, preset=6),\n",
    "        \"decompress\": lzma.decompress,\n",
    "    })\n",
    "\n",
    "    # Optional codecs\n",
    "    brotli_spec = importlib.util.find_spec(\"brotli\")\n",
    "    if brotli_spec:\n",
    "        import brotli\n",
    "\n",
    "        algos.append({\n",
    "            \"name\": \"brotli-q5\",\n",
    "            \"compress\": lambda b: brotli.compress(b, quality=5),\n",
    "            \"decompress\": brotli.decompress,\n",
    "        })\n",
    "        algos.append({\n",
    "            \"name\": \"brotli-q11\",\n",
    "            \"compress\": lambda b: brotli.compress(b, quality=11),\n",
    "            \"decompress\": brotli.decompress,\n",
    "        })\n",
    "\n",
    "    zstd_spec = importlib.util.find_spec(\"zstandard\")\n",
    "    if zstd_spec:\n",
    "        import zstandard as zstd\n",
    "\n",
    "        def zstd_compress(level: int):\n",
    "            c = zstd.ZstdCompressor(level=level)\n",
    "            return lambda b: c.compress(b)\n",
    "\n",
    "        def zstd_decompress(b):\n",
    "            d = zstd.ZstdDecompressor()\n",
    "            return d.decompress(b)\n",
    "\n",
    "        algos.append({\n",
    "            \"name\": \"zstd-l3\",\n",
    "            \"compress\": zstd_compress(3),\n",
    "            \"decompress\": zstd_decompress,\n",
    "        })\n",
    "        algos.append({\n",
    "            \"name\": \"zstd-l10\",\n",
    "            \"compress\": zstd_compress(10),\n",
    "            \"decompress\": zstd_decompress,\n",
    "        })\n",
    "\n",
    "    lz4_spec = importlib.util.find_spec(\"lz4.frame\")\n",
    "    if lz4_spec:\n",
    "        import lz4.frame\n",
    "\n",
    "        algos.append({\n",
    "            \"name\": \"lz4-default\",\n",
    "            \"compress\": lz4.frame.compress,\n",
    "            \"decompress\": lz4.frame.decompress,\n",
    "        })\n",
    "\n",
    "    return algos\n",
    "\n",
    "\n",
    "ALGORITHMS = _build_algorithms()\n",
    "print(\"Algorithms:\")\n",
    "for a in ALGORITHMS:\n",
    "    print(f\"- {a['name']}\")\n"
   ],
   "id": "b6342cb662c8176",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithms:\n",
      "- zlib-l1\n",
      "- zlib-l6\n",
      "- zlib-l9\n",
      "- gzip-l6\n",
      "- bz2-l9\n",
      "- lzma-p6\n",
      "- lz4-default\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T00:56:18.251174Z",
     "start_time": "2026-02-21T00:55:37.600521Z"
    }
   },
   "source": [
    "def benchmark_throughput(func, payload: bytes, min_seconds: float = 0.25, min_runs: int = 3):\n",
    "    \"\"\"Return throughput in MiB/s and median single-run latency in ms.\"\"\"\n",
    "    total_bytes = 0\n",
    "    runs = []\n",
    "    t_start = time.perf_counter()\n",
    "\n",
    "    while len(runs) < min_runs or (time.perf_counter() - t_start) < min_seconds:\n",
    "        t0 = time.perf_counter()\n",
    "        func(payload)\n",
    "        dt = time.perf_counter() - t0\n",
    "        runs.append(dt)\n",
    "        total_bytes += len(payload)\n",
    "\n",
    "    elapsed = max(sum(runs), 1e-9)\n",
    "    mib_s = (total_bytes / (1024 * 1024)) / elapsed\n",
    "    median_ms = statistics.median(runs) * 1000\n",
    "    return mib_s, median_ms\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for pyd_path in PYD_FILES:\n",
    "    raw = pyd_path.read_bytes()\n",
    "    raw_size = len(raw)\n",
    "\n",
    "    for algo in ALGORITHMS:\n",
    "        compressed = algo[\"compress\"](raw)\n",
    "        round_trip = algo[\"decompress\"](compressed)\n",
    "        if round_trip != raw:\n",
    "            raise ValueError(f\"Round-trip mismatch for {algo['name']} on {pyd_path.name}\")\n",
    "\n",
    "        c_mib_s, c_ms = benchmark_throughput(algo[\"compress\"], raw)\n",
    "\n",
    "        # Decompression throughput is normalized by original (uncompressed) bytes.\n",
    "        d_mib_s_by_compressed, d_ms = benchmark_throughput(algo[\"decompress\"], compressed)\n",
    "        ratio = len(compressed) / raw_size\n",
    "        d_mib_s = d_mib_s_by_compressed / max(ratio, 1e-9)\n",
    "\n",
    "        results.append({\n",
    "            \"file\": pyd_path.name,\n",
    "            \"algo\": algo[\"name\"],\n",
    "            \"raw_bytes\": raw_size,\n",
    "            \"compressed_bytes\": len(compressed),\n",
    "            \"ratio\": ratio,\n",
    "            \"compress_mib_s\": c_mib_s,\n",
    "            \"decompress_mib_s\": d_mib_s,\n",
    "            \"compress_median_ms\": c_ms,\n",
    "            \"decompress_median_ms\": d_ms,\n",
    "        })\n",
    "\n",
    "print(f\"Collected {len(results)} rows ({len(PYD_FILES)} files x {len(ALGORITHMS)} algos).\")\n"
   ],
   "id": "5019738143849fe5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 49 rows (7 files x 7 algos).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T00:56:18.285378600Z",
     "start_time": "2026-02-21T00:56:18.253175600Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def fmt_size(n):\n",
    "    return f\"{n / (1024 * 1024):.3f}\"\n",
    "\n",
    "\n",
    "def print_table(rows, headers):\n",
    "    widths = [len(h) for h in headers]\n",
    "    for row in rows:\n",
    "        for i, v in enumerate(row):\n",
    "            widths[i] = max(widths[i], len(str(v)))\n",
    "\n",
    "    line = \" | \".join(h.ljust(widths[i]) for i, h in enumerate(headers))\n",
    "    sep = \"-+-\".join(\"-\" * widths[i] for i in range(len(headers)))\n",
    "    print(line)\n",
    "    print(sep)\n",
    "    for row in rows:\n",
    "        print(\" | \".join(str(v).ljust(widths[i]) for i, v in enumerate(row)))\n",
    "\n",
    "\n",
    "# Per-file best ratio\n",
    "print(\"Per-file best compression ratio (lower is better):\")\n",
    "for p in PYD_FILES:\n",
    "    file_rows = [r for r in results if r['file'] == p.name]\n",
    "    best = min(file_rows, key=lambda r: r['ratio'])\n",
    "    print(\n",
    "        f\"- {p.name:35} {best['algo']:12} ratio={best['ratio']:.4f} \"\n",
    "        f\"size={fmt_size(best['compressed_bytes'])} MiB\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Aggregate weighted metrics by algorithm\n",
    "agg = defaultdict(lambda: {\n",
    "    'raw_total': 0,\n",
    "    'compressed_total': 0,\n",
    "    'compress_weighted': 0.0,\n",
    "    'decompress_weighted': 0.0,\n",
    "    'compress_ms': [],\n",
    "    'decompress_ms': [],\n",
    "})\n",
    "\n",
    "for r in results:\n",
    "    a = agg[r['algo']]\n",
    "    a['raw_total'] += r['raw_bytes']\n",
    "    a['compressed_total'] += r['compressed_bytes']\n",
    "    a['compress_weighted'] += r['compress_mib_s'] * r['raw_bytes']\n",
    "    a['decompress_weighted'] += r['decompress_mib_s'] * r['raw_bytes']\n",
    "    a['compress_ms'].append(r['compress_median_ms'])\n",
    "    a['decompress_ms'].append(r['decompress_median_ms'])\n",
    "\n",
    "summary = []\n",
    "for algo, a in agg.items():\n",
    "    raw_total = a['raw_total']\n",
    "    summary.append({\n",
    "        'algo': algo,\n",
    "        'ratio': a['compressed_total'] / max(raw_total, 1),\n",
    "        'compress_mib_s': a['compress_weighted'] / max(raw_total, 1),\n",
    "        'decompress_mib_s': a['decompress_weighted'] / max(raw_total, 1),\n",
    "        'compress_median_ms': statistics.median(a['compress_ms']),\n",
    "        'decompress_median_ms': statistics.median(a['decompress_ms']),\n",
    "    })\n",
    "\n",
    "print(\"\\nAggregate (weighted by input bytes):\")\n",
    "rows = [\n",
    "    (\n",
    "        s['algo'],\n",
    "        f\"{s['ratio']:.4f}\",\n",
    "        f\"{s['compress_mib_s']:.1f}\",\n",
    "        f\"{s['decompress_mib_s']:.1f}\",\n",
    "        f\"{s['compress_median_ms']:.2f}\",\n",
    "        f\"{s['decompress_median_ms']:.2f}\",\n",
    "    )\n",
    "    for s in sorted(summary, key=lambda s: s['ratio'])\n",
    "]\n",
    "print_table(rows, [\n",
    "    'algo',\n",
    "    'ratio',\n",
    "    'compress MiB/s',\n",
    "    'decompress MiB/s',\n",
    "    'compress median ms',\n",
    "    'decompress median ms',\n",
    "])\n",
    "\n",
    "\n",
    "print(\"\\nTop 3 by ratio:\")\n",
    "for s in sorted(summary, key=lambda s: s['ratio'])[:3]:\n",
    "    print(f\"- {s['algo']:12} ratio={s['ratio']:.4f}\")\n",
    "\n",
    "print(\"\\nTop 3 by compression speed:\")\n",
    "for s in sorted(summary, key=lambda s: s['compress_mib_s'], reverse=True)[:3]:\n",
    "    print(f\"- {s['algo']:12} compress={s['compress_mib_s']:.1f} MiB/s\")\n",
    "\n",
    "print(\"\\nTop 3 by decompression speed:\")\n",
    "for s in sorted(summary, key=lambda s: s['decompress_mib_s'], reverse=True)[:3]:\n",
    "    print(f\"- {s['algo']:12} decompress={s['decompress_mib_s']:.1f} MiB/s\")\n"
   ],
   "id": "174f15a709562095",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-file best compression ratio (lower is better):\n",
      "- harvest1.cp312-win_amd64.pyd        lzma-p6      ratio=0.3624 size=0.094 MiB\n",
      "- harvest2.cp312-win_amd64.pyd        lzma-p6      ratio=0.3571 size=0.096 MiB\n",
      "- harvest3.cp312-win_amd64.pyd        lzma-p6      ratio=0.3339 size=0.098 MiB\n",
      "- harvest4.cp312-win_amd64.pyd        lzma-p6      ratio=0.2664 size=0.106 MiB\n",
      "- harvest5.cp312-win_amd64.pyd        lzma-p6      ratio=0.1653 size=0.134 MiB\n",
      "- harvest6.cp312-win_amd64.pyd        lzma-p6      ratio=0.0912 size=0.227 MiB\n",
      "- harvest7.cp312-win_amd64.pyd        lzma-p6      ratio=0.0643 size=0.595 MiB\n",
      "\n",
      "Aggregate (weighted by input bytes):\n",
      "algo        | ratio  | compress MiB/s | decompress MiB/s | compress median ms | decompress median ms\n",
      "------------+--------+----------------+------------------+--------------------+---------------------\n",
      "lzma-p6     | 0.0980 | 11.1           | 160.0            | 67.12              | 5.66                \n",
      "bz2-l9      | 0.1589 | 8.6            | 88.7             | 29.14              | 8.60                \n",
      "zlib-l9     | 0.1905 | 11.7           | 535.6            | 38.15              | 1.19                \n",
      "zlib-l6     | 0.1925 | 37.8           | 475.0            | 15.44              | 1.29                \n",
      "gzip-l6     | 0.1925 | 38.1           | 475.7            | 13.23              | 1.43                \n",
      "zlib-l1     | 0.2040 | 157.1          | 476.1            | 4.97               | 1.35                \n",
      "lz4-default | 0.3325 | 1905.4         | 2444.4           | 0.50               | 0.08                \n",
      "\n",
      "Top 3 by ratio:\n",
      "- lzma-p6      ratio=0.0980\n",
      "- bz2-l9       ratio=0.1589\n",
      "- zlib-l9      ratio=0.1905\n",
      "\n",
      "Top 3 by compression speed:\n",
      "- lz4-default  compress=1905.4 MiB/s\n",
      "- zlib-l1      compress=157.1 MiB/s\n",
      "- gzip-l6      compress=38.1 MiB/s\n",
      "\n",
      "Top 3 by decompression speed:\n",
      "- lz4-default  decompress=2444.4 MiB/s\n",
      "- zlib-l9      decompress=535.6 MiB/s\n",
      "- zlib-l1      decompress=476.1 MiB/s\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
